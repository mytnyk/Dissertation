
% інформаційні технології -> кібернетика -> штучний інтелект -> машинне навчання
%                            кібернетика -> теорія керування -> ідентифікація систем

\section{Задача прогнозування стохастичних процесів}

\subsection{Поняття емпіричного прогнозування стохастичних процесів}

Під емпіричним моделюванням будемо розуміти статистичне узагальнення
і наближення математичними формулами даних спостережень. Результатом
емпіричного моделювання є емпірична модель. Відповідно емпіричне
прогнозування це побудова прогнозу на основі емпіричної моделі. Якщо
мова йде про деякий процес, то будемо говорити про емпіричне
моделювання і прогнозування процесу, якщо про систему, яка
представляє цей процес, то про ідентифікацію системи. Під системою
будемо розуміти деяку сукупність взаємодіючих елементів, які
доцільно розглядати як єдине ціле. Все, що не входить в дану
систему, є по відношенню до неї зовнішнім середовищем. Система
підлягає впливу зі сторони середовища і, в свою чергу, сама впливає
на середовище. Перші впливи будемо називати вхідними факторами
(сигналами, змінними), другі --- вихідними факторами. Емпірична
математична модель {\em динамічної}, тобто функціонуючої в часі,
системи будується за результатами спостереження за вхідними і
вихідними сигналами. Процедура такої побудови і називається {\em
ідентифікацією} динамічних систем~\cite{Gorsky-Adler-Talalai}.
Класичне означення ідентифікації запропоноване Л.Заде у 1962 році:
``Ідентифікація полягає у відшуканні за вхідними і вихідними
сигналами деякої системи еквівалентної до неї системи із деякого
заданого класу''~\cite{Eikhoff-Vanechek}. Більш строгі математичні
означення динамічних систем можна знайти в збірнику робіт по
математичній теорії систем~\cite{Willems89}. Слід зазначити, що
задача побудови модельних рівнянь за даними спостережень належить до
класу {\em обернених} задач~\cite{Bezruchko-Smirnov}\footnote{Будемо
відрізняти обернені задачі побудови модельних рівнянь від задач
відновлення вхідного сигналу по відомому вихідному, які також
називають оберненими~\cite{DudgeonMersereau88}}. Як правило обернені
задачі є некоректно поставленими (за Адамаром), оскільки для них не
існує єдиного розв'язку.


В залежності від рівня апріорної інформації про модель процесу
говорять про ідентифікацію в широкому розумінні або ж у вузькому. З
метою охоплення широкого класу задач в роботі досліджується
ідентифікація в широкому розумінні, коли точна структура моделі не
відома. В роботі~\cite{Usov-Dubrov-Dmitrishin} ідентифікація в
широкому розумінні визначається як отримання або уточнення на основі
експериментальних даних математичної моделі цієї системи, яка
виражена на мові того чи іншого математичного апарату. Оскільки
дослідження будуть обмежені {\em пасивною} ідентифікацією, тобто
ідентифікацією систем, для яких неможливо поставити експеримент, то
мова буде йти не про експериментальні дані, а про дані спостережень.
Типовий приклад таких систем --- економічні, екологічні системи. Як
правило такі системи є {\em нестаціонарними}, тобто властивості
перетворення вхідних сигналів змінні в часі. Реакція нестаціонарної
системи залежить як від величини вхідного сигналу, так і від моменту
його проходження. До того ж значення вихідних функцій в деякий
момент часу залежать не тільки від поточних, але й від попередніх
значень вхідних функцій. Подібні системи називають {\em
інерційними}, або системами з пам'яттю. Період часу пам'яті може
бути різним. В залежності від величини часу пам'яті інерційні
системи можна розділити на системи зі скінченою та нескінченною
пам'яттю. Очевидно, що стаціонарна залежність між входом та виходом
може бути нелінійною, тож досліджуються {\em нелінійні} моделі
систем. За типом зв'язків системи також поділяють на {\em
стохастичні} (ймовірнісні) і {\em детерміновані} (регулярні). Як
правило для складних систем з багаторівневою ієрархічною структурою,
які функціонують в умовах невизначеності під впливом зовнішніх
факторів, суттєвою є випадкова складова (надалі вважаємо, що
складова шумів є адитивною і гомоскедастичною). Такі системи є
стохастичними. Виділення систематичної (закономірної,
детермінованої) складової стохастичного процесу полягає у
відновленні функціональної залежності між вхідними та вихідними
факторами. Надалі будемо розглядати стохастичні системи з одним
вихідним фактором.

\subsubsection{Узагальнена задача відновлення стохастичної залежності}

Узагальнена задача відновлення стохастичної залежності формально
поставлена у наступному вигляді. Нехай задані дані спостережень
$\mathcal{D}=\{\left(y_j,\mathbf{x}_j\right):j=1,\ldots,N\}$, де
$\mathbf{x}=(x^1,\ldots,x^n)^\top\in\mathcal{X}\subseteq\mathbb{R}^n$,
$y\in\mathcal{Y}\subseteq\mathbb{R}$. Висувається гіпотеза про
існування стохастичної залежності, відповідно до якої кожному
вектору $\mathbf{x}$ ставиться у відповідність число $y$, отримане
за допомогою випадкового випробування за законом $P(y|\mathbf{x})$.
Задача відновлення стохастичної залежності полягає у відшуканні
умовної щільності розподілу $P(y|\mathbf{x})$ на основі скінченої
вибірки даних $\mathcal{D}$. Дана обернена задача некоректно
поставлена і зводиться до пошуку апостеріорного прогнозного
розподілу $P(y|\mathbf{x},\mathcal{D})$, який є наближенням реальної
стохастичної залежності. Наскільки близьким буде таке наближення
залежить від повноти даних спостережень. Емпіричне моделювання а
також навчання в цьому випадку це процес побудови апостеріорного
прогнозного розподілу $P(y|\mathbf{x},\mathcal{D})$, або його
математичного сподівання, тобто функції регресії
$y(\mathbf{x})=\mean{y_x}=\int yP(y|\mathbf{x},\mathcal{D})dy$.
Процес побудови функції регресії також будемо називати відновленням
регресії.

Постановка задачі в такому вигляді поєднує ідентифікацію систем в
теорії керування та машинне навчання в теорії штучного інтелекту. Це
дає нам можливість одночасно застосовувати методи досліджень обох
теоретичних розділів кібернетики.

\subsection{Представлення стохастичного процесу як нелінійного
динамічного процесу з шумом}

Як правило, детермінована складова стохастичного процесу це
нелінійний динамічний процес. Розглянемо клас нелінійних динамічних
систем, які в загальному випадку можна представити в просторі станів
як
\begin{equation}\label{General-StateSpase-Model}
\left\{
\begin{array}{l}
\mathbf{z}(t+1)=\mathbf{g}\left(\mathbf{z}(t),\mathbf{u}(t)\right)
\\
\mathbf{y}(t)=\mathbf{h}\left(\mathbf{z}(t),\mathbf{u}(t)\right)
\end{array}\right.,
\end{equation}
де $t$ --- змінна часу, $\mathbf{z}(t)\in\mathcal{Z}$ ---
внутрішній стан системи, $\mathbf{u}(t)\in\mathcal{U}$ --- вхідний
сигнал, $\mathbf{y}(t)\in\mathcal{Y}$ --- вихід системи,
$\mathbf{g}:\mathcal{Z}\times\mathcal{U}\rightarrow\mathcal{Z}$
--- нелінійна перехідна функція, $\mathbf{h}:\mathcal{Z}\times\mathcal{U}\rightarrow\mathcal{Y}$
--- нелінійна функція виходу. Дослідження обмежуються випадком, де $\dim \mathcal{Y} = 1$, тобто
$\mathbf{y}(t)\equiv y(t)$
--- скалярна функція. Такі моделі ще називають моделями зі скалярним
відгуком~\cite{Gorsky-Adler-Talalai}. Для побудови моделей складних
систем, для яких апріорі невідомі фізичні взаємозв'язки типу рівнянь
Максвела або ж інші причиноутворюючі процеси, безпосереднє
використання~(\ref{General-StateSpase-Model}) не є зручним. Якщо
відомі інформація або дані про вхідні та вихідний сигнали в
достатній кількості і якості (повноті), тоді невідомі взаємозв'язки
можна наблизити емпіричними парадигмами, які є основою класичної
статистичної теорії оцінювання.
Показано~\cite{Leontaritis-Billings}, що якщо
система~(\ref{General-StateSpase-Model}) може бути описана у
скінченновимірному просторі станів і коли вона знаходиться достатньо
близько до своєї точки рівноваги, то її можна представити у вигляді
моделі вхід-вихід:
\begin{multline*}
y(t) = f\bigl(y(t-1), \ldots, y(t-n_y), \mathbf{u}(t),
\mathbf{u}(t-1),
\ldots, \mathbf{u}(t-n_u),\\
 e(t-1), \ldots, e(t-n_e), \mathbf{w}\bigr) + e(t),
\end{multline*}
де $f$ --- деяке нелінійне відображення, $n_y$, $n_u$, $n_e$
--- натуральні числа, які визначають запізнення реакції системи,
$\mathbf{w}$ --- невідомий вектор параметрів.

Хоча був отриманий більш строгий критерій взаємних перетворень
представлень системи між моделлю у просторі станів і моделлю
вхід-вихід для випадку нескінченно гладких функцій $\mathbf{g}$,
$\mathbf{h}$~\cite{Foley-Sadegh}, проте подальші дослідження в
дисертаційній роботі не розглядають представлення у просторі станів.
Альтернативним напрямком є цікава стаття~\cite{Rivals-Personnaz}, де
запропоновано використання саме моделі простору стану для
моделювання нейронної мережі як чорного ящика. Широкий спектр
методів ідентифікації нелінійних систем в просторі станів
представлено в роботі В.Вердульта~\cite{Verdult}.

Надалі, як правило, будемо мати справу з представленням нелінійних
динамічних систем у вигляді наступного відображення:
\begin{equation}\label{General-Black-Box-Model}
y(t)=f\bigl(\mathbf{x}(t),\mathbf{w}\bigr)+e(t),
\end{equation}
де $\mathbf{x}(t) = (y(t-1), \ldots, y(t-n_y), \mathbf{u}(t),
\ldots, \mathbf{u}(t-n_u), e(t-1), \ldots, e(t-n_e))^\top$ ---
вектор регресорів. Це представлення узагальнює широкий спектр
відомих моделей:
\begin{list}{$\circ$}{}
\item Нелінійні регресійні моделі зі скінченим відгуком на
імпульс, які використовують тільки регресори $\mathbf{u}(t-k)$. До
цього класу зокрема відносяться моделі у вигляді непараметричного
ряду Вольтера~\cite{Guo}:
$$
y(t)=g^m\bigl(u(t),u(t-1),\ldots,u(t-n_u)\bigr)+e(t),
$$
де $g^m$ --- нелінійна функція степеню $m$. \item Нелінійні
авторегресійні моделі, які використовують регресори
$\mathbf{u}(t-k)$, $y(t-k)$. Типова модель --- параметричний ряд
Вольтера вигляду:
$$
y(t)=g^m\bigl(u(t),u(t-1),\ldots,u(t-n_u)\bigr)-a_1y(t-1)-\ldots-a_{n_y}y(t-n_y)+e(t).
$$
До цього класу відносяться і нелінійні диференціальні
рівняння~\cite{Guo}:
$$
y(t)=b_0u(t)+b_1u(t-1)+\ldots+b_nu(t-n_u)+g^m\bigl(y(t-1),\ldots,y(t-n_y)\bigr)+e(t).
$$
А також нелінійні моделі Вінера-Гамерштейна з нелінійним каскадом
$z=g(u)$ у вигляді:
\begin{multline*}
 y(t)=-a_1y(t-1)-\ldots-a_{n_y}y(t-n_y)+\\
+b_1g(u(t-1)) +\ldots+b_{n_u}g(u(t-n_u)) + e(t).
\end{multline*}
\item Нелінійні авторегресійні моделі з ковзним середнім, які
використовують регресори $\mathbf{u}(t-k)$, $y(t-k)$, $e(t-k)$. На
практиці для збільшення гнучкості таких моделей шум виноситься в
залишки наступним чином:
$$
y(t)=f\left(\mathbf{x}(t), \mathbf{w}\right) + C(q^{-1})e(t),
$$
де $C$ --- деякий лінійний фільтр, $q^{-1}$ --- оператор
запізнення реакції системи.
\end{list}

\subsection{Помилки ідентифікації нелінійних динамічних систем з шумом}

Нехай задана вибірка спостережень
$\mathcal{D}=\left\{\left(y(t),\mathbf{x}(t)\right):t=1,\ldots,N\right\}$
об'ємом $N$. В процесі ідентифікації нелінійна параметризована
динамічна модель $\mathcal{M}(\mathbf{x}(t),\mathbf{w})$ намагається
перетворити вхідний сигнал $\mathbf{u}(t)$ у вихідний $y(t)$, який
спотворений шумовою складовою $e(t)$, за допомогою наближення
$f(t)=\mathcal{M}(\mathbf{x}(t),\mathbf{w})$. Загальна концепція
ідентифікації нелінійної динамічної системи зображена на
рис.~\ref{fig:IdentProcess}.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=5cm]{CHAPTER1/EPS/IdentProcess.pdf}}}
{\centerline{\psfig{figure=CHAPTER1/EPS/IdentProcess.eps,height=5cm}}}
\caption{Процес і модель.}\label{fig:IdentProcess}
\end{figure}
Задачу такого наближення слід розділити на дві категорії:
\begin{list}{\checkmark}{}
\item Структурна ідентифікація. Це пошук оптимальної структури
моделі $\mathcal{M}$, в тому числі оптимального числа параметрів
моделі, що визначається розмірністю вектора $\mathbf{w}$. Як правило
задача структурної ідентифікації пов'язана з проблемами
комбінаторної оптимізації, складність яких
швидко зростає із числом вхідних змінних. %
\item Параметрична ідентифікація. Якщо відома структура моделі і кількість
параметрів, задача наближення зводиться до відшукання таких
оптимальних значень цих параметрів, які дають найкраще за заданим
критерієм наближення оцінки $f(t)$ реального процесу $y(t)$. Для
цього мінімізується так званий емпіричний ризик $R_{emp}(f)$, про
який буде йти мова далі.
\end{list}
Припустимо, що за допомогою структурної ідентифікації була вибрана
деяка структура моделі $\mathcal{M}$, яка визначає простір
(ансамбль) потенційних функцій $\mathcal{M}=\{f\}$. Кожній функції
відповідає свій вектор параметрів $\mathbf{w}$. Оскільки простір, в
якому знаходиться реальний процес $y(t)$, не співпадає і, як
правило, містить в собі простір потенційних функцій, то виникає {\em
помилка наближення} моделі, пов'язана з неточним вибором структури
моделі. Крім цього виникає {\em помилка оцінювання} моделі пов'язана
з вибором неоптимальних параметрів моделі. Таким чином {\em
узагальнена помилка} складається з помилки наближення та помилки
оцінювання. На рис.~\ref{fig:ModellingError} зображені взаємозв'язки
помилок.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=7cm]{CHAPTER1/EPS/ModellingError.pdf}}}
{\centerline{\psfig{figure=CHAPTER1/EPS/ModellingError.eps,height=7cm}}}
\caption{Помилки моделювання.}\label{fig:ModellingError}
\end{figure}
Наявність таких помилок пов'язана з дилемою зміщення-варіації
(точності-гладкості) моделі, де зміщення моделі призводить до
помилки наближення, а варіація моделі призводить до помилки
оцінювання.

\subsubsection{Паритет зміщеності та варіації моделі}

Розглянемо математичне сподівання квадрату похибки наближення:
\begin{multline*}
\meanl{f-y}^2= \meanl{f-\mean{f}+\mean{f}-y}^2=\\
=\meanl{f-\mean{f}}^2+\meanl{\mean{f}-y}^2+2
\meanl{(f-\mean{f})(\mean{f}-y)}.
\end{multline*}
Оскільки функція $y$ детермінована і $\meanl{f-\mean{f}}=0$, то
остаточно маємо:
$$
\meanl{f-y}^2=\underbrace{\meanl{f-\mean{f}}^2}_{\mbox{варіація}}
+\underbrace{\meanl{\mean{f}-y}^2}_{\mbox{зміщення}}.
$$
Перший доданок характеризує {\em варіацію} моделі, тобто показує
наскільки модель чутлива до різних вибірок, або ж іншими словами
--- відображає коваріацію між вектором параметрів і оптимальним вектором
параметрів.
%Якщо варіація адитивного шуму складає $\sigma^2$ і $q$
%--- кількість параметрів моделі, то варіацію можна приблизно оцінити як
%$\sigma^2\frac{q}{N}$~\cite{Geman-Bienenstock-Doursat}.
Другий доданок характеризує {\em зміщення} моделі, тобто показує як
середня модель заданої структури відрізняється від реальної системи.
Модель є незміщеною, якщо вона збігається до реальної системи при
$N\rightarrow\infty$. В той час як варіація моделі пов'язана з її
точністю, зміщення моделі пов'язано з її
складністю~\cite{Geman-Bienenstock-Doursat}.

Для зменшення середньо-квадратичної помилки необхідно зменшувати
одночасно зміщення і варіацію моделі. Однак збільшення числа
параметрів моделі приводить з одного боку до зменшення зміщення
моделі, а з іншого до збільшення варіації моделі і можливо погіршує
її прогнозуючі властивості. При цьому модель стає перевизначеною
надмірною кількістю параметрів. Звідси слідує відомий принцип
ощадливості моделі: найкраща модель --- це модель з найменшою
кількістю ступенів свободи, яка дозволяє із заданою точністю
генерувати вибірку даних.

З метою розкриття невизначеності зміщення-варіації моделі
застосовуються різноманітні методи регуляризації некоректних задач
ідентифікації, які будуть розглянуті в наступному підрозділі.

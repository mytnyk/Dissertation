
\section{Методи розв'язання некоректних задач навчання}

З точки зору теорії ймовірності задачу ідентифікації можна
сформулювати як задачу навчання, де необхідно відтворити імплікації
за їх наслідками. В подальшому, задачі ідентифікації нелінійних
динамічних систем також будемо називати задачами (машинного)
навчання. При цьому для стаціонарних систем очевидна повна
відповідність, якщо дискретну змінну часу представити індексом у
впорядкованій вибірці даних, а для нестаціонарних систем змінну часу
можна віднести до додаткового вхідного фактору. Тож надалі
позначення залежності змінних від часу ми вживати не будемо.

\subsection{Принцип мінімізації структурного ризику}

Якість наближеної моделі отриманої на основі вхідних та вихідних
даних може визначатися як наступний $L^2$ функціонал справжнього
ризику~\cite{Vapnik-NIPS}:
\begin{equation}\label{TrueRisk}
R_{true}(f)=\iint_{\mathcal{X}\times\mathcal{Y}}\bigl(y-f(\mathbf{x})\bigr)^2P(\mathbf{x},y)d\mathbf{x}dy,
\end{equation}
де $P(\mathbf{x},y)$ --- сумісна щільність розподілу, яка апріорі
невідома. Основна задача --- знайти таку функцію $f_{true}$ серед
деякого скінченого класу функцій $\mathcal{M}$, для якої ризик
$R_{true}(f)$ мінімальний:
$$
f_{true}=\arg\min_{f\in\mathcal{M}}R_{true}(f).
$$
Справжній ризик $R_{true}$ має зміст узагальненої помилки.

\subsubsection{Мінімізація емпіричного ризику}

Згідно з принципом мінімізації емпіричного ризику, задачу
мінімізації невідомого справжнього ризику $R_{true}$ можна замінити
на мінімізацію відомого емпіричного ризику $R_{emp}$, який може бути
визначений наступним чином~\cite{Vapnik-79}:
\begin{equation}\label{EmpiricalRisk}
R_{emp}(f)=\frac{1}{N}\sum_{j=1}^N\bigl(y_j-f(\mathbf{x}_j)\bigr)^2.
\end{equation}
При цьому $R_{emp}(f)<R_{true}(f)$. Емпіричний ризик є спроможним,
якщо
$$
\lim_{N\rightarrow\infty}\min_{f\in\mathcal{M}}R_{emp}(f)
=\min_{f\in\mathcal{M}}R_{true}(f).
$$
Мінімізація емпіричного ризику відпрацьовує бездоганно у випадку
коли функція $f_{true}$, яка точно відображає реальний процес,
належить простору $\mathcal{M}$. Але на жаль, складні процеси не
можуть бути описані за допомогою тривіальних залежностей. Для
дослідження таких питань як: за яких умов припустима мінімізація
емпіричного ризику і наскільки гарні наближення можна отримати з її
допомогою, розвинена спеціальна статистична теорія
навчання~\cite{Bousquet-Boucheron-Lugosi,Balakrishnan},
започаткована В.Н.Вапником і
А.Я.Червоненкісом~\cite{Vapnik-Chervonenkis}. Цікавий розвиток
статистична теорія навчання знайшла також в роботах
К.В.Воронцова~\cite{Voroncov-1,Voroncov-2,Voroncov-3}.

\subsubsection{Мінімізація структурного ризику}

В~\cite{Goodman-Rourke} можна знайти означення розмірності
Вапника-Червоненкіса для простору значень.  Як правило це означення
поширюється на простір функцій наступним
чином~\cite{Wikipedia-VCdimension}:
\begin{defi}
Розмірністю Вапника-Червоненкіса (ВЧ) деякого класу функцій
$\mathcal{M}$ називається максимальний об'єм вибірки даних $h$
такий, що для будь-яких значень вибірки існує така функція $f$ з
цього класу, яка дає нульову помилку.
\end{defi}
Очевидно, що для лінійних моделей розмірність ВЧ співпадає з числом
ступенів свободи моделей (числом параметрів моделі). Наприклад, для
найпростішої лінійної стаціонарної моделі вигляду $y(x)=ax+b$
ВЧ-розмірність $h=2$, оскільки через будь-які дві точки можна
провести пряму.

Показано, що з ймовірністю $(1-\kappa)$ верхня межа справжнього
ризику складає:
$$
R_{true}(f)\leqslant
R_{emp}(f)+\sqrt{\frac{h(\ln(2N/h)+1)-\ln(\kappa/4)}{N}}.
$$
З цього можна зробити очевидний висновок, що для стовідсоткової
впевненості в структурі моделі необхідна нескінчена вибірка даних.
Верхню межу справжнього ризику можна інтерпретувати як суму
емпіричного ризику і інтервалу довіри до моделі, який виражає
ступінь її складності~(рис.~\ref{fig:VCDimension}).
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=8cm]{CHAPTER1/EPS/VCDimension.pdf}}}
{\centerline{\psfig{figure=CHAPTER1/EPS/VCDimension.eps,height=8cm}}}
\caption{Верхня межа справжнього ризику.}\label{fig:VCDimension}
\end{figure}
Принцип мінімізації структурного ризику є формальним методом для
вибору оптимальної структури моделі для скінченої вибірки даних. Він
полягає в наступному.

Задається структура вкладених класів потенційних моделей:
$$
\mathcal{M}_1\subset\mathcal{M}_2\subset
\mathcal{M}_3\subset\cdots\subset\mathcal{M}_k\subset\cdots,
$$
де модель $\mathcal{M}_k=\{f_k(\mathbf{x},\mathbf{w}):
\mathbf{w}\in\mathcal{F}_k, \dim\mathcal{F}_k=q_k\}$ має скінчену ВЧ
розмірність $h_k$ (наприклад модель $\mathcal{M}_k$ може визначати
множину поліномів ступеню не менше ніж $k$). Таким чином множина
потенційних моделей ранжується в залежності від складності (ємності)
тієї чи іншої моделі, оскільки:
$$
h_1\leqslant h_2\leqslant h_3\leqslant \cdots\leqslant
h_k\leqslant\cdots
$$
Для заданої вибірки даних вибирається така модель $\mathcal{M}_k$,
для якої досягається мінімальна верхня межа справжнього ризику.

Оскільки в роботі розглядаються складні нелінійні процеси, а
статистична теорія навчання обмежена простими (лінійними) моделями,
де ВЧ розмірність може бути обчислена аналітично, то для
застосування цієї теорії необхідно або робити наближення для ВЧ
розмірності, або лінеаризувати нелінійні моделі.

\subsection{Регуляризація Тихонова}\label{sec-Regul-approach}

Для визначення псевдооберненої матриці $\mathbf{A}^+$ до матриці $A$
над дійсними числами можна використовувати границю обернених:
$$
\mathbf{A}^+=\lim_{\alpha\rightarrow0}(\mathbf{A}^\top
\mathbf{A}+\alpha\mathbf{I})^{-1}\mathbf{A}^\top=
\lim_{\alpha\rightarrow0}\mathbf{A}^\top(\mathbf{A}^\top
\mathbf{A}+\alpha\mathbf{I})^{-1}.
$$
Аналогічна ідея використовується в тихоновській регуляризації
некоректних задач~\cite{Tichonov-Arsenin-Timonov,Tichonov-Arsenin},
зокрема для розв'язання погано обумовлених систем лінійних рівнянь
$\mathbf{A}\mathbf{w}=\mathbf{y}$ відносно вектора невідомих змінних
$\mathbf{w}$. Метод регуляризації Тихонова зводить початкову задачу
до задачі мінімізації наступного функціоналу:
\begin{equation}\label{Tichonov-functional}
\|\mathbf{A}\mathbf{w}-\mathbf{y}\|^2+\alpha\|\mathbf{w}-\mathbf{w}_0\|^2,
\end{equation}
де $\|\cdot\|$ --- евклідова норма. Тоді регуляризований розв'язок
можна знайти у формі:
$$
\mathbf{w}_{reg}=(\mathbf{A}^\top
\mathbf{A}+\alpha\mathbf{I})^{-1}(\mathbf{A}^\top\mathbf{y}+\alpha\mathbf{w}_0).
$$
Таким чином в основі регуляризації лежить залучення додаткової
апріорної інформації про розв'язок --- шукають розв'язок близький до
$\mathbf{w}_0$. Постановка може мати більш загальний характер, якщо
задати (апріорну) матрицю коваріації $\mathbf{\Omega}_a$ для вектору
невідомих змінних. В нашому випадку $\mathbf{\Omega}_a=\mathbf{I}$,
що відповідає регуляризації нульового порядку~\cite{Bossley-TechR}.
В контексті некоректних задач навчання
функціонал~(\ref{Tichonov-functional}) має зміст регуляризованого
ризику:
\begin{equation}\label{Tichonov-Regularization}
R_{reg}(f)=NR_{emp}(f)+\alpha R_f(f),
\end{equation}
де $\alpha>0$ --- коефіцієнт регуляризації (Тихонова), а складова
$R_f(f)$ виражає апріорні сподівання щодо очікуваної функції.
Коефіцієнт регуляризації контролює баланс зміщення-варіації. Так,
при збільшенні значення коефіцієнту регуляризації зменшується
варіація моделі, але збільшується зміщення. Для розв'язання такого
класу задач в роботі Н.В.Панової~\cite{Panova} запропонований
ефективний регуляризований рекурентний МНК, де складова $R_{f}(f)$
виступає в ролі стабілізуючого функціоналу. Інший регуляторний
підхід для побудови стійких алгоритмів відновлення залежностей на
основі робастних методів згладжуючої сплайн-регресії розроблений
В.М.Остропицьким~\cite{Ostropytsky,Vasylenko}. Задача мінімізації
ризику~(\ref{Tichonov-Regularization}) також відома як задача
відновлення гребеневої або реберної (ridge)
регресії~\cite{Enukov86}, де коефіцієнт регуляризації $\alpha$
називають параметром гребеня.

Нехай невідома залежність $f$ описується лінійною в параметрах
моделлю в деякому просторі $\mathcal{F}$:
$$
y=f(\mathbf{x})=\mathbf{a}^\top\mathbf{w},\quad
\mathbf{a}=\mathbf{\Phi}(\mathbf{x}),\quad\mathbf{\Phi}:\mathcal{X}\rightarrow\mathcal{F}.
$$
Для заданої вибірки даних
$\mathcal{D}=\{\left(y_j,\mathbf{x}_j\right):j=1,\ldots,N\}$
позначимо $\mathbf{y}=(y_1,\ldots,y_N)^\top$, де
$y_j=f(\mathbf{x}_j)$. Тоді задача навчання зводиться до розв'язання
системи лінійних рівнянь $\mathbf{y}=\mathbf{A}\mathbf{w}$, де
матриця $\mathbf{A}=(\mathbf{a}_1,\ldots,\mathbf{a}_N)^\top$. Як
правило припускають, що $\mathbf{w}_0=\mathbf{0}$, тоді
регуляризований розв'язок має вигляд:
$$
\mathbf{w}_{reg}=\mathbf{H}^{-1}\mathbf{A}^\top\mathbf{y},\quad\mathbf{H}=\mathbf{A}^\top
\mathbf{A}+\alpha\mathbf{I}.
$$
де матриця $\mathbf{H}$ є гессіаном ризику, оскільки її можна
отримати після подвійного диференціювання ризику
$\mathbf{H}\propto\nabla^2_\mathbf{w}R_{reg}(\mathbf{w})$. Оскільки
кожному вектору параметрів відповідає певна функція, то позначення
$R_{reg}(\mathbf{w})$ і $R_{reg}(f)$ є рівноцінними. Складові
регуляризованого вектору параметрів відображено на
рис.~\ref{fig:ContourLikelihood}.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=8cm]{CHAPTER1/EPS/ContourLikelihood.pdf}}}
{\centerline{\psfig{figure=CHAPTER1/EPS/ContourLikelihood.eps,height=8cm}}}
\caption{Контури правдоподібності і власні вектори в масштабі
власних чисел для $\mathbf{A}^\top\mathbf{A}$ з центром
$\mathbf{w}_{ml}$, для $\mathbf{\Omega}_a^{-1}$ з центром
$\mathbf{w}_0$, для $\mathbf{H}$ з центром
$\mathbf{w}_{reg}$.}\label{fig:ContourLikelihood}
\end{figure}
Відповідно оцінку відгуку можна представити у вигляді:
$$
\hat{\mathbf{y}}=\mathbf{S}\mathbf{y},
$$
де $\mathbf{S}=\mathbf{A}\mathbf{H}^{-1}\mathbf{A}^\top$
--- лінійний оператор згладжування. У випадку відсутності
механізму регуляризації оператор згладжування вироджується в
проекційну матрицю
$\mathbf{S}\equiv\mathbf{P}=\mathbf{A}(\mathbf{A}^\top
\mathbf{A})^{-1}\mathbf{A}^\top$. Проекційну матрицю можна
інтерпретувати як оператор проекції, який проектує вектори на
підпростір елементів стовпців матриці
$\mathbf{A}$~\cite{Sgurovsky-Bidyuk}. Як легко показати, кількість
ступенів свободи $\acute{q}$ нерегуляризованої моделі, яка співпадає
з числом незалежних змінних (кількістю ефективних параметрів за
Дж.Муді~\cite{Moody}) дорівнює
$$
\acute{q}=\rang\mathbf{P}=\tr\mathbf{P}.
$$
Це слідує з того, що власні числа проекційної матриці рівні або 0
або 1. Регуляризація змінює число ступенів свободи моделі:
\begin{equation}\label{Effective-params-via-matrices}
\acute{q}=\tr\mathbf{S}=\tr\left(\mathbf{A}\mathbf{H}^{-1}\mathbf{A}^\top
\right)= \tr\left(\mathbf{A}^\top\mathbf{A}\mathbf{H}^{-1}\right).
\end{equation}
Звідси маємо:
\begin{equation}\label{Effective-params-via-eigens}
\acute{q}=\sum_{i=1}^q\frac{\gamma_i}{\gamma_i+\alpha},
\end{equation}
де $\gamma_i$ --- власні числа автокореляційної матриці
$\mathbf{A}^\top\mathbf{A}$, дійсні та невід'ємні. Якщо $\gamma_i$
невелике в порівнянні з $\alpha$, то функція правдоподібності
виражає невелику довіру цьому напрямку в просторі параметрів,
вважаючи за краще використовувати апріорно заданий розподіл
параметрів. Якщо $\gamma_i$ істотно більше ніж $\alpha$, то вибірка
даних значно більше впливає на відповідний напрямок в просторі
параметрів.

\subsection{Байєсівський підхід до навчання}
%і принцип максимальної правдоподібності

Основною задачею байєсівського підходу є знаходження апостеріорного
прогнозного розподілу на основі даних спостережень
$\mathcal{D}=\{(y_j,\mathbf{x}_j):j=1,\ldots,N\}$. Нехай
систематична складова стохастичної залежності може бути представлена
деякою функцією $f$ моделі $\mathcal{M}$ із простору моделей
$\mathcal{H}$. Виникають питання: яким чином визначити простір
моделей $\mathcal{H}$, як визначити оптимальну модель $\mathcal{M}$
з цього простору, і яким чином визначити параметри цієї моделі,
тобто конкретну функцію $f$. Байєсівський аналіз дає відповідь на
останні два запитання.

\subsubsection{Проблема вибору моделі}

Нехай задано простір моделей $\mathcal{H}$. Тоді, відповідно до
байєсівського аналізу, в якості оптимальної вибирається модель з
найбільшою апостеріорною ймовірністю $P(\mathcal{M}|\mathcal{D})$.
За формулою Байєса:
$$
P(\mathcal{M}|\mathcal{D})=\frac{P(\mathcal{D}|\mathcal{M})P(\mathcal{M})}{P(\mathcal{D})},
$$
де $P(\mathcal{M})$ --- апріорний розподіл моделей в просторі
$\mathcal{H}$, $P(\mathcal{D})$ --- апріорна ймовірність виникнення
самої вибірки даних, яка після отримання даних спостережень відіграє
роль лише нормуючої константи. Припускаючи рівномірний розподіл
моделей, моделі ранжуються за величиною їх підтвердження
$P(\mathcal{D}|\mathcal{M})$ (англ. evidence), яке виражає здатність
моделі $\mathcal{M}$ генерувати дані $\mathcal{D}$. На
рис.~\ref{fig:BayesianEvidence} показані величини підтверджень даних
$\mathcal{D}_1$, $\mathcal{D}_2$ моделями $\mathcal{M}_1$,
$\mathcal{M}_2$.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=7cm]{CHAPTER1/EPS/BayesianEvidence.pdf}}}
{\centerline{\psfig{figure=CHAPTER1/EPS/BayesianEvidence.eps,height=7cm}}}
\caption{Порівняння величини байєсівського підтвердження для різних
моделей.}\label{fig:BayesianEvidence}
\end{figure}
Підтвердження, також відоме як маргінальна правдоподібність,
визначається як:
\begin{equation}\label{Evidence-density}
P(\mathcal{D}|\mathcal{M})=\int_\mathcal{M}P(\mathcal{D},f|\mathcal{M})df,
\end{equation}
де сумісна щільність розподілу $P(\mathcal{D},f|\mathcal{M})=
P(\mathcal{D}|f,\mathcal{M})P(f|\mathcal{M})$. Ймовірність
$P(\mathcal{D}|f,\mathcal{M})$ виражає здатність функції $f$
генерувати дані $\mathcal{D}$ і називається правдоподібністю. Надалі
вважається, що випадкова складова стохастичної залежності є
адитивним шумом і $y_j=f(\mathbf{x}_j)+\delta_j$, де $\delta_j$ ---
незалежні і однаково розподілені за законом
$P(\delta|f,\mathcal{M})$ випадкові величини. Правдоподібність у
цьому випадку має вигляд:
$$
P(\mathcal{D}|f,\mathcal{M})=\prod_{j=1}^NP(\delta_j|f,\mathcal{M}),
$$
Нехай апріорна щільність розподілу функцій $f$ моделі $\mathcal{M}$,
згідно з принципом максимальної
ентропії~\cite{Jaynes-68}\footnote{Згідно з принципом максимальної
ентропії знаходять розподіл, який з одного боку максимізує
інформаційну ентропію процесу, а з іншого задовольняє наявній
апріорній інформації про процес. В класі розподілів із заданими
першими двома моментами таким оптимальним апріорним розподілом є
нормальний розподіл.}, задана у вигляді багатовимірного нормального
розподілу з математичним сподіванням $\mathbf{b}$ і матрицею
коваріації $\mathbf{K}$:
\begin{equation}\label{NormalPriorFunc}
P(f|\mathcal{M})=\mathcal{N}(\mathbf{f}|\mathbf{b},\mathbf{K}),\quad
\mathbf{f}=\left(f(\mathbf{x}_1),\ldots,f(\mathbf{x}_N)\right)^\top.
\end{equation}
Оскільки підтвердження~(\ref{Evidence-density}) може бути обчислене
аналітично тільки в найпростіших випадках, наприклад у випадку
нормального шуму, то застосовують різноманітні методи наближення.
Серед них метод Монте-Карло~\cite{Neal-97}, розповсюдження
сподівань~\cite{Minka-PhD}, варіаційні методи, метод
Лапласа~\cite{Mackay-99}.

\subsubsection{Проблема визначення параметрів моделі}

Для визначення параметрів моделі байєсівський аналіз розглядає
апостеріорний розподіл функцій:
$$
P(f|\mathcal{D},\mathcal{M})=\frac{P(\mathcal{D},f|\mathcal{M})}{P(\mathcal{D}|\mathcal{M})}.
$$
Словами:
$$
\mbox{Апостеріорний
розподіл}=\frac{\mbox{Правдоподібність}\times\mbox{Апріорний
розподіл}}{\mbox{Підтвердження}}.
$$
В цьому випадку апостеріорний прогнозний розподіл, який виражає
апостеріорні сподівання щодо значень $y$, обчислюється як інтеграл
по апостеріорній невизначеності функцій:
$$
P(y|\mathbf{x},\mathcal{D})=\int_\mathcal{M}
P(y|\mathbf{x},f,\mathcal{M})P(f|\mathcal{D},\mathcal{M})df.
$$
Використовуючи так звану оцінку максимальної апостеріорної
ймовірності функції (МАП), яка дає наближення математичного
сподівання апостеріорного прогнозного розподілу модою апостеріорного
розподілу функцій, знаходяться оптимальні значення параметрів
моделі:
$$
y(\mathbf{x})\approx f_{mp}(\mathbf{x})=\arg\max_f
P(f|\mathcal{D},\mathcal{M}).
$$
Графічна інтерпретація байєсівського висновку за
С.А.Шумським~\cite{Shumsky} в контексті навчання зображена на
рис.~\ref{fig:BayesianLearning}.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=9cm]{CHAPTER1/EPS/BayesianLearning.pdf}}}
{\centerline{\psfig{figure=CHAPTER1/EPS/BayesianLearning.eps,height=9cm}}}
\caption{Байєсівське навчання.} \label{fig:BayesianLearning}
\end{figure}
Зазначимо, що, слідуючи класичній байєсівській теорії прийняття
рішень, ризик прийняти оцінку $\hat{f}$ для справжньої функції
$f_{true}$ дорівнює:
$$
R_L(\hat{f})=\int_\mathcal{M}L(\hat{f},f)P(f|\mathcal{D},\mathcal{M})df,
$$
де функція втрат $L(\hat{f},f)$ характеризує втрати пов'язані з
різницею між оцінкою і невідомою справжньою
функцією~\cite{Gorodetsky03}. Це слідує з мінімізації справжнього
байєсівського ризику, який узагальнює~(\ref{TrueRisk}), як
математичного сподівання функції втрат~\cite{Voronin92}:
\begin{multline*}
R_{true}(\hat{f})=\mean{L(\hat{f},f)}=\iint
L(\hat{f},f)P(f,\mathcal{D}|\mathcal{M})dfd\mathcal{D}=\\
=\int\left(\int_\mathcal{M}
L(\hat{f},f)P(f|\mathcal{D},\mathcal{M})df\right)P(\mathcal{D}|\mathcal{M})d\mathcal{D}.
\end{multline*}
Тож, для заданої вибірки $\mathcal{D}$ оптимальна байєсівська оцінка
мінімізує як справжній ризик $R_{true}$ так і так званий умовний
байєсівський ризик $R_L$. Якщо визначити функцію втрат як абсолютну
помилку $L(\hat{f},f)=|\hat{f}-f|$, то оптимальною байєсівською
оцінкою буде значення медіани апостеріорного розподілу функцій.
Оскільки медіана це точка, для якої сума абсолютних значень різниці
всіх значень менше суми різниць для будь-якої іншої точки. Якщо ж в
якості функції втрат взяти середньо-квадратичну помилку
$L(\hat{f},f)=|\hat{f}-f|^2$, то оптимальною байєсівською оцінкою
буде значення математичного сподівання апостеріорного розподілу
функцій.
%Медиана – это такая точка на числовой оси, для которой сумма
%абсолютных значений разности всех значений меньше суммы разностей
%для любой другой точки. Если именно так определять понятие ошибки,
%то медиана дает минимальную ошибку. Если же ошибка определяется как
%сумма квадратов разностей, то минимальную ошибку дает среднее.
Як показано в монографії Е.Джейнса~\cite{Jaynes-Logic}, МАП оцінка
$f_{mp}$, тобто мода апостеріорного розподілу функцій, буде
оптимальною байєсівською оцінкою лише у випадку, коли функція втрат
визначена як:%1-(дельта функція Дiрака)
$$
L(\hat{f},f)=\lim_{k\rightarrow0}|\hat{f}-f|^k= \left\{
\begin{array}{ll}0, & \hat{f}=f\\1, & \hat{f}\neq
f\end{array}\right..
$$
Хоч серед прибічників чистого байєсівського висновку такий підхід
часто критикують, надалі в роботі буде використовуватися саме МАП
оцінка. Змістовна теорія байєсівського оцінювання в теорії
статистичних висновків досить детально викладена в роботах
Ш.Закса~\cite{Zaks} та М.Де~Гроота~\cite{DeGroot-74}.

Відповідно до МАП оцінки найбільш ймовірна функція $f_{mp}$
визначається як:
\begin{multline}\label{MAPlogEstimate}
f_{true}\sim f_{mp}=\arg\max_f\bigl(\log
P(f|\mathcal{D},\mathcal{M})\bigr)= \\
=\arg\min_f\bigl(-\log P(\mathcal{D}|f,\mathcal{M})-\log
P(f|\mathcal{M})\bigr).
\end{multline}
Оскільки підтвердження моделі $P(\mathcal{D}|\mathcal{M})$ не
залежить від окремої функції і в даному випадку виконує роль
нормуючої константи.

Якщо припустити рівномірність апріорного розподілу функцій
$P(f|\mathcal{M})$, то максимізація апостеріорної ймовірності
$P(f|\mathcal{D},\mathcal{M})$ еквівалентна максимізації функції
правдоподібності:
$$
f_{ml}=\arg\min_f\bigl(-\log P(\mathcal{D}|f,\mathcal{M}))\bigr).
$$
За умови, що розподіл шуму є нормальним з нульовим середнім і з
дисперсією $\var{\delta}=\sigma^2$, тобто
$P(\delta|f,\mathcal{M})=\mathcal{N}(\delta|0,\sigma^2)$, тоді
критерій максимальної правдоподібності в протилежному логарифмічному
масштабі записується у вигляді~\cite{Kirichkov}:
\begin{equation}\label{log-likelihood-criteria}
-\ln P(\mathcal{D}|f,\mathcal{M})=
N\ln(\sqrt{2\pi}\sigma)+\frac{1}{2\sigma^2}\sum_{j=1}^N\delta_j^2
\stackrel{f}{\longrightarrow}\min.
\end{equation}
Мінімізація~(\ref{log-likelihood-criteria}) еквівалентна мінімізації
емпіричного ризику~(\ref{EmpiricalRisk}) Відзначимо, що метод
найменших квадратів знаходить максимум правдоподібності з нормально
розподіленим шумом. Критерій~(\ref{log-likelihood-criteria}) можна
узагальнити на випадок довільної коваріації помилок $\mathbf{R}\sim
r_{ij}=\cov(\delta_i,\delta_j)$~\cite{Purser-Parrish}:
$$
-\ln
P(\mathcal{D}|f,\mathcal{M})=N\ln(\sqrt{2\pi}\sigma)+\frac{1}{2}\ln\det
\mathbf{R}+\frac{1}{2}\delta^\top \mathbf{R}^{-1}\delta,
$$
де вектор $\delta=(\delta_1,\ldots,\delta_N)^\top$. Оскільки
визначник коваріації не залежить від функцій $f$, то фактично задача
знаходження максимальної апостеріорної ймовірності зводиться до
мінімізації наступної квадратичної форми:
$$
\delta^\top \mathbf{R}^{-1}\delta\stackrel{f}{\longrightarrow}\min.
$$
Проте, оскільки апріорний розподіл функцій $P(f|\mathcal{M})$
відіграє роль регуляризуючого елементу і забезпечує контроль над
відношенням зміщення-варіація моделі, припущення щодо його
рівномірності не є коректним. Тож, надалі ми будемо вважати
апріорний розподіл нормально розподіленим у
формі~(\ref{NormalPriorFunc}).

\subsubsection{Наближення підтвердження методом Лапласа. Підтвердження гіперпараметрів.}\label{sec-Baes-Approach-To-Regularization}

Опишемо метод Лапласа для наближення підтвердження. Нехай апріорний
розподіл функцій $f(\mathbf{x})$ моделі
$\mathcal{M}(\mathbf{x},\mathbf{w})$ визначається нормальним
розподілом параметру $\mathbf{w}$ наступним чином:
$P(f|\mathcal{M})=\mathcal{N}\left(\mathbf{w}|\mathbf{w}_0,\mathbf{\Omega}_a\right)$.
Щільність розподілу шуму також нормальна з дисперсією $\sigma^2$:
$P(\delta|f,\mathcal{M})=\mathcal{N}\left(\delta|0,\beta^{-1}\right)$,
параметр $\beta=\sigma^{-2}$. Тоді, згідно з МАП
оцінкою~(\ref{MAPlogEstimate}), отримаємо:
\begin{multline*}
f_{mp}=\arg\min_f -\frac{N}{2}\ln\frac{\beta}{2\pi}+\frac{\beta}{2}\sum_{j=1}^N\delta_j^2-\\
-\frac{q}{2}\ln\frac{1}{2\pi}+\frac{1}{2}\ln\det\mathbf{\Omega}_a+\frac{1}{2}(\mathbf{w}-\mathbf{w}_0)^\top\mathbf{\Omega}_a^{-1}(\mathbf{w}-\mathbf{w}_0).
\end{multline*}
Зауважимо, що ця задача еквівалентна мінімізації регуляризованого
ризику:
\begin{equation}\label{General-Regularization}
R_{reg}(\mathbf{w})=\frac{\beta}{2}NR_{emp}(\mathbf{w})+
\frac{1}{2}R_{\mathbf{w}}(\mathbf{w}),
\end{equation}
де
$$
R_{emp}(\mathbf{w})=\frac{1}{N}\sum_{j=1}^N\delta_j^2,\quad
R_{\mathbf{w}}(\mathbf{w})=(\mathbf{w}-\mathbf{w}_0)^\top\mathbf{\Omega}_a^{-1}(\mathbf{w}-\mathbf{w}_0).
$$
У відповідності з~(\ref{Tichonov-Regularization}) коефіцієнт
регуляризації $\alpha=\beta^{-1}$. Тобто $\beta$ є оберненим
коефіцієнтом регуляризації. Параметр $\beta$ також називають
гіперпараметром. При цьому регуляризований розв'язок
$\mathbf{w}_{reg}$ відповідає МАП оцінці
$\mathbf{w}_{mp}=\mathbf{w}_{reg}$.

Для знаходження підтвердження~(\ref{Evidence-density}) необхідно
обчислити інтеграл:
\begin{equation}\label{Evidence-expansion-2}
P(\mathcal{D}|\mathcal{M})=\sqrt{\left(\frac{\beta}{2\pi}\right)^{N}\left(\frac{1}{2\pi}\right)^{q}
\frac{1}{\det\mathbf{\Omega}_a}}\cdot\int_\mathcal{F}
\exp{\left(-R_{reg}(\mathbf{w})\right)}d\mathbf{w}.
\end{equation}
Слідуючи методу наближень Лапласа~\cite{Mackay-99}, розкладемо
регуляризований ризик в ряд Тейлора другого порядку в точці
$\mathbf{w}_{mp}$:
\begin{multline}\label{Risk-Taylor}
R_{reg}(\mathbf{w})\approx
R_{reg}(\mathbf{w}_{mp})+\frac{\partial
R_{reg}(\mathbf{w}_{mp})}{\partial\mathbf{w}}(\mathbf{w}_{mp}-\mathbf{w})+\\
+\frac{1}{2}(\mathbf{w}_{mp}-\mathbf{w})^\top \frac{\partial^2
R_{reg}(\mathbf{w}_{mp})}{\partial\mathbf{w}^2}(\mathbf{w}_{mp}-\mathbf{w}).
\end{multline}
Друга складова в правій частині дорівнює нулю, оскільки точка
$\mathbf{w}_{mp}$ є точкою мінімуму регуляризованого ризику за
побудовою. Таким чином~(\ref{Risk-Taylor}) запишеться:
$$
R_{reg}(\mathbf{w})\approx R_{reg}(\mathbf{w}_{mp})+
\frac{1}{2}(\mathbf{w}_{mp}-\mathbf{w})^\top
\mathbf{H}(\mathbf{w}_{mp}-\mathbf{w}).
$$
де гесcіан
$\mathbf{H}=\beta\mathbf{A}^\top\mathbf{A}+\mathbf{\Omega}_a^{-1}$.
Враховуючи розклад Тейлора
підтвердження~(\ref{Evidence-expansion-2}) можна записати у
наступній формі:
$$
P(\mathcal{D}|\mathcal{M})\approx\sqrt{\left(\frac{\beta}{2\pi}\right)^{N}\left(\frac{1}{2\pi}\right)^{q}
\frac{1}{\det\mathbf{\Omega}_a}}\cdot
e^{-R_{reg}(\mathbf{w}_{mp})}\int_\mathcal{F}
e^{-\frac{1}{2}(\mathbf{w}_{mp}-\mathbf{w})^\top
\mathbf{H}(\mathbf{w}_{mp}-\mathbf{w})}d\mathbf{w}.
$$
Обчисливши інтеграл, який відповідає багатовимірному розподілу
Гауса, отримуємо:
$$
P(\mathcal{D}|\mathcal{M})\approx\sqrt{\left(\frac{\beta}{2\pi}\right)^{N}\left(\frac{1}{2\pi}\right)^{q}
\frac{1}{\det\mathbf{\Omega}_a}}\cdot
e^{-R_{reg}(\mathbf{w}_{mp})}\cdot
\sqrt{\frac{(2\pi)^q}{\mathbf{\det\mathbf{H}}}}.
$$
Слідуючи Маккею~\cite{MacKay-NIPS}, цей результат можна
інтерпретувати як:
$$
\underbrace{P(\mathcal{D}|\mathcal{M})}_{\mbox{Підтвердження}}\approx
\underbrace{P(\mathcal{D}|\mathbf{w}_{mp},\mathcal{M})}_{\mbox{Правдоподібність}}\cdot
\underbrace{P(\mathbf{w}_{mp}|\mathcal{M})(2\pi)^{q/2}\mathbf{\det\mathbf{H}^{-1/2}}}_{\mbox{Фактор
Окхема}}.
$$
Тобто підтвердження дорівнює добутку максимальної правдоподібності
на так званий множник Окхема\footnote{Термін походить від відомого в
літературі леза Окхема --- Occam's Razor principle (William of
Ockham): ``Numquam ponendo est pluritas sine necessitate. [Latin]''.
Що буквально означає --- не потрібно застосовувати складне, якщо не
має необхідності. Більш звичний переклад --- маючи дві однаково
ефективні теорії, вибираємо простішу; найпростіше пояснення як
правило є найкращим.}, який має зміст відношення апостеріорної
невизначеності вектору параметрів до апріорної~\cite{Gull-88}. Це
означає, що байєсівський критерій вибору моделі є простим розширенням
критерію максимальної правдоподібності.
%Occam's Razor principle (William of Ockham)
%Numquam ponendo est pluritas sine necessitate. [Latin]
%Multiples should never be used if not necessary.
%"Shave off" (omit) unnecessary entities in explanations. But a
%more commonly used translation is:
%Given two equally predictive theories, choose the simpler.
%The simplest explanation is usually the best.
Підтвердження у зворотному логарифмічному масштабі запишеться так:
\begin{equation}\label{EvidenceLogDetailedExpansion}
-\ln
P(\mathcal{D}|\mathcal{M})\approx-\frac{N}{2}\ln\frac{\beta}{2\pi}
+\frac{1}{2}\ln\det\mathbf{\Omega}_a+\frac{1}{2}\ln\det\mathbf{H}+R_{reg}(\mathbf{w}_{mp}).
\end{equation}

Для знаходження найбільш ймовірного значення гіперпараметру $\beta$
необхідно знайти максимум підтвердження
$P(\mathcal{D}|\mathcal{M})$. Це можна зробити наприклад за
допомогою ітеративного методу Маккея~\cite{Mackay-99}. Припустимо
що, інтуїтивно задавши довільне значення гіперпараметру $\beta$, за
допомогою регуляризованого критерію~(\ref{General-Regularization})
було знайдене регуляризоване значення $\mathbf{w}_{mp}$. Необхідно
дати рекомендації щодо того, яким чином необхідно змінити значення
гіперпараметру для збільшення підтвердження. Змістовна інтерпретація
такої процедури оптимізації зображена на
рис.~\ref{fig:GeneralizationProps}.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=6cm]{CHAPTER1/EPS/GeneralizationProps.pdf}}}
{\centerline{\psfig{figure=CHAPTER1/EPS/GeneralizationProps.eps,height=6cm}}}
\caption{Якість моделі в залежності від гіперпараметрів.}
\label{fig:GeneralizationProps}
\end{figure}
Зауважимо, що $\ln\det\mathbf{H}=\tr\ln\mathbf{H}$. Тоді, взявши
похідну в~(\ref{EvidenceLogDetailedExpansion}) відносно
гіперпараметру $\beta$ і прирівнявши її нулю, отримаємо:
$$
-\frac{N}{2}\cdot\frac{1}{\beta}+\frac{1}{2}\tr\left(\mathbf{H}^{-1}\mathbf{A}^\top\mathbf{A}\right)+\frac{N}{2}R_{emp}(\mathbf{w}_{mp})=0.
$$
Звідси можна визначити переоціночну ітеративну формулу для
гіперпараметру у формі:
$$
\beta(i+1)=\frac{N-\beta(i)\tr\left(\mathbf{H}^{-1}\mathbf{A}^\top\mathbf{A}\right)}{NR_{emp}(\mathbf{w}_{mp})},\quad
$$
При цьому $\mathbf{w}_{mp}=\mathbf{H}^{-1}\mathbf{A}^\top
\mathbf{y}$ і гессіан
$\mathbf{H}=\beta(i)\mathbf{A}^\top\mathbf{A}+\mathbf{\Omega}_a^{-1}$.

\subsection{Перевірка моделей на адекватність}

\subsubsection{Адекватність моделі регресії. Критерій Фішера}

%\begin{defi}
%Випадкова величина $\chi_n^2=z_1^2+z_2^2+\cdots+z_n^2$ називається
%$\chi_n^2$ з $n$ ступенями свободи, якщо $z_1,z_2,\ldots,z_n$ ---
%незалежні випадкові величини, кожна з яких розподілена нормально з
%нульовим середнім і одиничною дисперсією~\cite{Bendat-Pirsol}.
%\end{defi}
%\noindent Щільність $\chi_n^2$ розподілу визначається як:
%$$
%p(\chi^2)=\left[2^{n/2}\Gamma\left(\frac{n}{2}\right)\right]^{-1}(\chi^2)^{n/2-1}e^{-\chi^2/2}.
%$$
%Зручно позначити величину $\chi_n^2$, яка відповідає ймовірності
%$P(\chi_n^2)=1-\alpha$ символом $\chi_{n,\alpha}^2$, тоді
%справедливо наступне:
%$$
%\int_{\chi_{n,\alpha}^2}^\infty
%p(\chi^2)d\chi^2=P[\chi_n^2>\chi_{n,\alpha}^2]=\alpha.
%$$
%\begin{defi}
%Випадкова величина
%$$
%F_{n_1,n_2}=\frac{y_1n_2}{y_2n_1}
%$$
%називається величиною $F$ з $n_1$ і $n_2$ ступенями свободи, якщо
%$y_1$ і $y_2$ --- незалежні випадкові величини, з розподілами
%$\chi_{n_1}^2$ $\chi_{n_2}^2$ відповідно.
%\end{defi}
%\noindent Щільність розподілу $F_{n_1,n_2}$ визначається як:
%$$
%p(F_{n_1,n_2})=\frac{\Gamma[(n_1+n_2)/2](n_1/n_2)^{n_1/2}F^{n_1/2-1}}
%{\Gamma(n_1/2)\Gamma(n_2/2)[1+(n_1F/n_2)]^{(n_1+n_2)/2}}.
%$$
%Зручно позначити величину $F_{n_1,n_2}$ ($F$-розподіл) з $n_1$ і
%$n_2$ ступенями свободи, яка відповідає ймовірності
%$P(F_{n_1,n_2})=1-\alpha$ символом $F_{n_1,n_2,\alpha}$, тоді можна
%записати:
%$$
%\int_{F_{n_1,n_2,\alpha}}^\infty
%p(F)dF=P[F_{n_1,n_2}>F_{n_1,n_2,\alpha}]=\alpha.
%$$
%Це дозволяє зробити висновок про те що, якщо розрахована
%$F$-статистика $F_{n_1,n_2}$ більше табличного значення
%$F_{n_1,n_2,\alpha}$ з рівнем значущості $\alpha$, то з ймовірністю
%$1-\alpha$ можна стверджувати про факт залежності випадкових величин
%$y_1$ та $y_2$.

%Як показано в роботі~\cite{Bendat-Pirsol} величина:
%$$
%F_{n_x,n_y}=\frac{s_x^2\sigma_y^2}{s_y^2\sigma_x^2},
%$$
%є $F$-розподілом, де $s_x^2$ --- вибіркова дисперсія нормально
%розподіленої випадкової величини $x$ з відомою дисперсією
%$\sigma_x^2$; $s_y^2$
%--- вибіркова дисперсія нормально розподіленої випадкової величини
%$y$ з відомою дисперсією $\sigma_y^2$.

В класичній задачі перевірки моделі регресії на значущість
розраховується наступна
$F$-статистика~\cite{Bendat-Pirsol,Pustylnik68}:
$$
F=\frac{s_x^2}{s_e^2},\quad
s_x^2=\frac{1}{q}\sum_{i=1}^N(f_i-\bar{y})^2,\quad
s_e^2=\frac{1}{N-q}\sum_{i=1}^N(y_i-f_i)^2
$$
де $N$ --- об'єм вибірки, $q$ --- кількість параметрів регресійної
моделі. $s_x^2$ характеризує факторну (пояснювальну) дисперсію,
$s_e^2$ характеризує дисперсію залишків. Тож, якщо $F$-статистика
більше табличного значення $F_{q,N-q,\alpha}$, то з ймовірністю
$1-\alpha$ можна стверджувати про значимість регресії і наявність
тренду, а також про адекватність моделі регресії за критерієм
Фішера.

\subsubsection{Застосування критерію Фішера для порівняння моделей}

Розглянемо дві моделі:
$$
\begin{array}{l}
\mathcal{M}_0=\{f_0(\mathbf{x},\mathbf{w}_0):
\mathbf{w}_0\in\mathcal{W}_0\},\quad\dim\mathcal{W}_0=q_0,\\
\mathcal{M}_1=\{f_1(\mathbf{x},\mathbf{w}_1):
\mathbf{w}_1\in\mathcal{W}_1\supset\mathcal{W}_0\},\quad\dim\mathcal{W}_1=q_1.
\end{array}
$$
Позначимо простір
$\mathcal{W}^\perp:\mathcal{W}_1=\mathcal{W}_0\oplus\mathcal{W}^\perp$,
$\dim\mathcal{W}^\perp=s=q_1-q_0$. Висунемо нуль гіпотезу про те, що
для заданої вибірки даних $\mathcal{D}$ вектор параметрів
$\mathbf{w}^\perp$ із простору $\mathcal{W}^\perp$ дорівнює нулю:
$$
H_0:\mathbf{w}^\perp=\mathbf{0},\quad
\mathbf{w}^\perp\in\mathcal{W}^\perp.
$$
Це в свою чергу означає що
$R_{emp}(\mathbf{w}_0)=R_{emp}(\mathbf{w}_1)$. І, відповідно,
альтернативна гіпотеза $H_1:\mathbf{w}^\perp\neq\mathbf{0}$. Мета
статистичного тесту полягає у визначенні факту: чи підтримує вибірка
даних більшу модель. При цьому $F$-статистика рівна:
$$
F=\frac{N-q_1}{N-q_0}\cdot\frac{R_{emp}(\mathbf{w}_0)}{R_{emp}(\mathbf{w}_1)},
$$
оскільки  $R_{emp}(\mathbf{w}_i)$ відповідає розподілу
$\chi^2_{N-q_i}$. Задавши рівень значущості $\alpha$, тобто
ймовірність відкинути гіпотезу $H_0$ при
$\mathbf{w}^\perp=\mathbf{0}$, можна порівняти $F$-статистику із
табличним значенням $F_{N-q_0,N-q_1,\alpha}$ і прийняти рішення про
справедливість нуль гіпотези, якщо розраховане значення менше
табличного.

%Загальна статистика для порівняння двох моделей в логарифмічному
%масштабі або логарифмічний коефіцієнт детермінації (ЛКД)
%визначається як:
%$$
%\mbox{ЛКД}=N\log\left(\frac{R_{emp}(\mathbf{w}_0)}{R_{emp}(\mathbf{w}_1)}\right).
%$$

%\subsubsection{Перевірка гіпотези}

%Наступна функція є мірою спроможності моделі генерувати вибірку
%даних:
%$$
%R_{reg}=N\log(R_{emp}(f))+qK(1),
%$$
%де $K(1)$ визначає параметр рівня значущості $\alpha$, який
%визначає ймовірність відмови від меншої моделі при порівнянні двох
%моделей зі ступенями свободи, що відрізняються на одиницю.

\subsubsection{Міра кількості інформації}

Відповідно до класифікації наведеної в
роботі~\cite{Baranovska-Lojko} %стор.29
існує декілька підходів до оцінювання кількості інформації:
статистичний, семантичний, прагматичний і структурний. Найбільш
поширений і розвинений статистичний підхід, засновником якого
вважається К.Шенон. К.Шенон ввів поняття кількості інформації як
міри невизначеності стану системи, яка знімається при отриманні
інформації~\cite{Shennon}. Кількісно виражена невизначеність
отримала назву {\em ентропії} (інформаційної ентропії) за аналогією
з подібним поняттям в статистичній механіці. При отриманні
інформації зменшується невизначеність, тобто ентропія системи. Однак
для оцінювання якості статистичних моделей прийнято дотримуватися
поняття ентропії за Больцманом (статистичної ентропії), яка
відображає міру ймовірності знаходження системи в однорідному стані.
Узагальнюючи поняття статистичної ентропії як логарифму ймовірності
отримання вибіркового розподілу з очікуваного, вводиться міра
близькості ймовірнісних розподілів із заданими щільностями $P_f(x)$
і $P_g(x)$ відома як дивергенція (відстань) Кульбака-Лейблера, або
інформація по Кульбаку~\cite{Kullback}:
$$
D_{KL}(P_g\|P_f)=\int
P_g(x)\log\left(\frac{P_g(x)}{P_f(x)}\right)dx.
$$
При цьому $D_{KL}(P_g\|P_f)\geqslant0$ і
$D_{KL}(P_g\|P_f)=0\Leftrightarrow P_g=P_f$. Величину
$-D_{KL}(P_g\|P_f)$ називають ентропією $P_g(x)$ по відношенню до
$P_f(x)$. Чим більше ентропія, тим краще $P_f(x)$ наближає $P_g(x)$.
Саму дивергенцію Кульбака-Лейблера називають негентропією (негативна
ентропія) $P_g(x)$ по відношенню до $P_f(x)$. Чим менше негентропія
тим краще $P_f(y)$ наближає $P_g(y)$.

Наведемо деякі відомі критерії вибору моделей на основі міри
кількості інформації:
\begin{list}{$\S$}{}
\item Інформаційний критерій Акаіке (ІКА):
$$
\mbox{ІКА}=N\ln(R_{emp}(f))+2q.
$$
В роботі~\cite{Eikhoff-Vanechek} показано, що значення ІКА співпадає
із подвійною середньою негентропією, і визначає міру неузгодженості
моделі з реальним процесом: $\mbox{ІКА}=2D_{KL}(P_{true}\|P_f)$.
%В контексті критерію перевірки
%гіпотези рівень значущості дорівнює 2.

\item Остаточна помилка прогнозування (ОПП) в логарифмічному
масштабі:
$$
\ln(\mbox{ОПП})=\ln(R_{emp}(f))+\ln\left(\frac{N+q}{N-q}\right).
$$
ОПП визначається як дисперсія помилки прогнозу на один крок вперед
за умови використання для прогнозу оцінок параметрів авторегресійної
моделі по МНК. Критерій мінімуму ОПП враховує як помилку пов'язану
із неточністю оцінювання параметрів так і помилку від заміни системи
моделлю~\cite{Eikhoff-Vanechek}. Критерій ОПП, а потім і ІКА були
розвинуті Х.Акаіке~\cite{Akaike}. Зазначимо, що мінімізація ІКА і
мінімізація ОПП це асимптотично еквівалентні процедури.

\item Байєсівська статистична міра значущості (БСМЗ)~\cite{Schwarz}:
$$
\mbox{БСМЗ}=N\ln(R_{emp}(f))+q\ln N.
$$
Ще одна назва цього критерію --- байєсівський інформаційний критерій
(БІК), або байєсівський інформаційний критерій Шварца, який вивів
асимптотичну апроксимацію для інтегрованої функції правдоподібності,
як ще називають байєсівське підтвердження, для слабо інформативного
апріорного розподілу функцій $P(f|\mathcal{M})$ на умовах
регулярності у вигляді:
$$
\log P(\mathcal{D}|\mathcal{M}) \approx \log
P(\mathcal{D}|f_{ml},\mathcal{M})-\frac{q}{2} \log N,
$$
де $q$ --- число вільних параметрів моделі $\mathcal{M}$, $f_{ml}$
--- оцінка максимальної правдоподібності для $f$, яка рівна:
$$
f_{ml}= \arg \max_{f} P(\mathcal{D}|f,\mathcal{M}).
$$

%http://www-math.univ-fcomte.fr/mixmod/statdoc_1_6/node21.html

\item Мінімальна довжина описання (МДО) за
Дж.Рісаненом~\cite{Rissanen}:
$$
\mbox{МДО}=\ln(R_{emp}(f))+q\frac{\ln N}{N}.
$$
%Цей критерій є частковим випадком критерію перевірки гіпотези, якщо
%визначити рівень значущості $\alpha=\ln N$ і
Цей критерій співпадає з байєсівською мірою
значущості~\cite{Bossley-TransR}.
\end{list}

Для порівняння регуляризованих моделей
(підрозділ~\ref{sec-Regul-approach}) розвинуті наступні критерії
вибору моделі, де замість кількості вільних параметрів моделі
використовується кількість ефективних параметрів.
\begin{list}{$\S$}{}
\item Узагальнена помилка прогнозування
(УПП)~\cite{Moody,Bossley-TechR}:
\begin{equation}\label{GPE}
\mbox{УПП}=R_{emp}(f)+2\sigma^2\frac{\acute{q}}{N}.
\end{equation}
де $\sigma^2$ --- варіація шуму, $\acute{q}$ --- кількість
ефективних параметрів.

\item Інформаційний критерій мережі (ІКМ)~\cite{Murata-Yoshizawa-Amari}:
\begin{equation}\label{NIC}
\mbox{ІКМ}=N\ln(R_{emp}(f))+2\acute{q}.
\end{equation}
ІКМ фактично є узагальненням критерію Акаіке, для випадку
регуляризації~(\ref{General-Regularization}). Цей критерій мінімізує
незміщену оцінку помилки прогнозу.
\end{list}

\subsubsection{Перехресна валідація (або перехресне обґрунтування)}\label{sec-cross_valid}

Підхід перехресного обґрунтування (англ. cross-validation) полягає у
розділенні наявної вибірки даних на дві вибірки: навчальну і
перевірочну. Процедура пошуку моделі перебирає задану кількість
структур моделей і вибирає модель з мінімальною помилкою на
перевірочній вибірці. Якщо перевірочна вибірка слідує безпосередньо
після навчальної, то говорять про випереджаючу валідацію (англ.
forward validation). Також застосовують так звану $k$-кратну
перехресну валідацію ($k$-fold cross-validation). В цьому випадку
вибірку ділять на $k$ приблизно рівних підмножин. Модель навчають
$k$ разів, кожен раз виключаючи з навчальної вибірки одну з
підмножин. У випадку якщо $k$ рівне об'єму вибірки, то має місце
перехресна валідація через виключення одного (англ. leave-one-out
cross-validation). Але такого роду підходи мають наступні недоліки:
\begin{list}{$\bullet$}{}
\item Як правило вибірка досить обмежена в розмірі і не покриває
вхідний простір. Тож, якщо не змінювати перевірочну вибірку, може
бути вибрана гіперчутлива модель. Тобто ідеально мати на кожен тест
нову перевірочну вибірку. %
\item Великі обчислювальні витрати.
Особливо у випадку $k$-кратної перехресної валідації.%
\item Одним із суттєвих недоліків випереджаючої валідації є той
факт, що безпосередньо останні наявні дані беруть участь лише в
пошуку структури моделі і не впливають на сам прогноз вибраної
моделі. Якщо припустити, що структура моделі відома, то останні дані
будуть просто ігноруватися.
\item Перехресна валідація це ``зашумлена'' міра адекватності
моделі. Тож складно обчислити оптимальні значення гіперпараметрів,
оскільки необхідно знайти екстремум функції шуму. На відміну,
наприклад, від байєсівського підтвердження, яке не є функцією шуму і
дозволяє обчислити градієнт відносно гіперпараметрів.
\end{list}
Більш ефективною є узагальнена перехресна валідація
(УПВ)~\cite{Golub-Heath-Wahba}:
$$
\log(\mbox{УПВ})=\log(R_{emp}(f))-2\log\left(1-\frac{q}{N}\right).
$$
Показано, що УПВ асимптотично еквівалентна перехресній валідації.

Зазначимо, що всі наведені критерії асимптотично
еквівалентні\footnote{В тому числі, за деяких додаткових припущень,
асимптотично еквівалентні метод перехресної валідації і критерій
Акаіке, про що згадується у Х.Акаіке~\cite{Eikhoff-Vanechek}. %стор.167
Асимптотична еквівалентність означає нескінченність вибірки даних
($N\rightarrow\infty$).}.
%That's cross-validation, and two things to emphasize about it are
%(1) it uses a noisy performance measure (the validation error); (2)
%it is hard to simultaneously control multiple tricky parameters with
%cross-validation because it is hard to search in a high-dimensional
%space for the optimum of a noisy function. In contrast, in Bayesian
%complexity control methods (1) we use the evidence which is not
%noisy a functions of the parameters; (2) we can find the GRADIENT of
%the `evidence' with respect to the parameters, so allowing search in
%high-dimensional complexity control spaces.

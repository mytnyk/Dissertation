

\section{Апробація ПРІАМ на еталонних моделях}

В цьому підрозділі ми розглянемо роботу ПРІАМ на відомих штучних та
реальних еталонних моделях нелінійної та лінійної регресій. Моделі
зібрані з декількох джерел. Проект StRD\footnote{Statistical
Reference Datasets: \url{http://www.itl.nist.gov/div898/strd/}}
містить еталонні моделі, які сертифіковані за кількістю ступенів
свободи (кількістю параметрів), показниками суми квадратів залишків
та F-статистики. Метою цього проекту є покращення якості
статистичного програмного забезпечення, надаючи еталонні вибірки
даних з сертифікованими результатами. Другим джерелом є база даних
для тестування алгоритмів машинного навчання~\cite{MLRepository}.
Також були використані дані з проекту Delve~\footnote{Data for
Evaluating Learning in Valid Experiments:
\url{http://www.cs.toronto.edu/~delve/}}.


\subsection{Модель Лонглі (Longley)}

Розглянемо модель, описану Дж.Лонглі~\cite{Longley} як типовий
приклад мультиколінеарної регресії (лінійна модель):
$$
y(\mathbf{x})=b_0+b_1x^1+b_2x^2+b_3x^3+b_4x^4+b_5x^5+b_6x^6.
$$
Змінні мають зміст наступних макроекономічних показників США з 1947
по 1962 рр.: $y$ --- число людей, які мають роботу; $x^1$ --- індекс
цін (неявний дефлятор валового національного продукту), 1954 рік ---
100\%; $x^2$ --- валовий національний продукт; $x^3$ --- число
безробітних; $x^4$ --- число військовослужбовців; $x^5$ ---
кількість дорослого населення (старші 14 років); $x^6$ --- рік.
Рис.~\ref{fig:longley}\footnote{Тут і далі на всіх рисунках крива
моделі РОВ проведена через точки вибірки за допомогою кубічної
сплайн-інтерполяції. Це не є точним зображенням відгуку але
коректно, оскільки РОВ будується як гладка апроксимація, що
проходить через задані точки.} відображає результат ідентифікації
ПРІАМ на основі 11 точок.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=8.5cm]{CHAPTER4/EPS/longley.pdf}}}
{\centerline{\psfig{figure=CHAPTER4/EPS/longley.eps,height=9cm}}}
\caption{ПРІАМ для моделі Лонглі: 1 --- прогноз, 2
--- реальні дані, 3 --- опорні вектори, 4 --- 95\% довірчий інтервал.}\label{fig:longley}
\end{figure}
Останні п'ять точок показують прогноз. Модель описується шістьма
опорними векторами. Повний розв'язок представлено в
таблиці~\ref{tbl:Solution-Longley}. Апріорна і оптимальна
конфігурації характеристичного простору моделі Лонглі мають
відповідно вигляд діагональних матриць:
$$
\mathbf{C}^{(0)}=\diag\{1,1,1,1,1,1\},\quad
\mathbf{C}^{(\cdot)}=\diag\{0,1,1,1,1,1\}.
$$
Також в таблиці~\ref{tbl:Solution-Longley} наведений ітеративний
процес пошуку оптимальних значень гіперпараметрів на основі
байєсівського підтвердження. Зокрема показані значення критерію
байєсівського підтвердження (КБП), ширини смуги нечутливості
$\tilde{\epsilon}$ на нормованих даних, оберненого коефіцієнту
регуляризації $\beta$, кількості опорних векторів $N_{sv}$,
емпіричного та регуляризованого ризику на навчальній вибірці,
середньо квадратичної помилки і середньої абсолютної помилки на
нормованій прогнозній вибірці. Розклад опорних векторів:
\begin{multline*}
f_{\mbox{opt}}(\mathbf{x})=0.56+11.2k(\mathbf{x}_{1},\mathbf{x})+20.4k(\mathbf{x}_{3},\mathbf{x})
-38.5k(\mathbf{x}_{4},\mathbf{x})-\\
-12k(\mathbf{x}_{6},\mathbf{x})+48.8k(\mathbf{x}_{10},\mathbf{x})-29.8k(\mathbf{x}_{11},\mathbf{x}).
\end{multline*}
Представлення моделі у формі Бернштейна:
\begin{multline*}
f_{\mbox{opt}}(\mathbf{x})=0.56+0.003\phi_0^1(x^2)-0.003\phi_1^1(x^2)
+0.22\phi_0^1(x^3)-0.22\phi_1^1(x^3)+\\+0.09\phi_0^1(x^4)
-0.09\phi_1^1(x^4)-0.38\phi_0^1(x^5)+0.38\phi_1^1(x^5)-0.42\phi_0^1(x^6)+0.42\phi_1^1(x^6).
\end{multline*}

\subsection{Модель Філіппеллі (Filippelli)}

Розглянемо іншу модель, яка є результатом досліджень
NIST\footnote{National Institute of Standards and Technology ---
\url{www.nist.gov}} і належить А.Філіппеллі (поліном 10-го порядку):
$$
y(t)=b_0+b_1x(t)+b_2x^2(t)+b_3x^3(t)+\ldots+b_{10}x^{10}(t)+e(t).
$$
Рис.~\ref{fig:filip} відображає результат ідентифікації ПРІАМ на
основі 33 точок.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=9cm]{CHAPTER4/EPS/filip.pdf}}}
{\centerline{\psfig{figure=CHAPTER4/EPS/filip.eps,height=9cm}}}
\caption{ПРІАМ для моделі Філіппеллі.} \label{fig:filip}
\end{figure}
Останні 49 точок показують прогноз. Модель описується 10 опорними
векторами. Повний розв'язок представлено в
таблиці~\ref{tbl:Solution-Filip}. Наведений ітеративний процес
пошуку оптимальних значень гіперпараметрів на основі байєсівського
підтвердження. Апріорна і оптимальна конфігурації характеристичного
простору моделі Філіппеллі мають відповідно вигляд:
$$
\mathbf{C}^{(0)}=\left(1\right),\quad
\mathbf{C}^{(\cdot)}=\left(9\right).
$$
Розклад опорних векторів:
\begin{multline*}
f_{\mbox{opt}}(x)=0.55-50k(x_{1},x)+16.6k(x_{2},x)
+26.1k(x_{7},x)+\\
-4.7k(x_{10},x)+50k(x_{14},x)-43.1k(x_{16},x)+\\
+0.5k(x_{22},x)-6.9k(x_{29},x)-6k(x_{31},x)+17.8k(x_{33},x).
\end{multline*}
Представлення моделі у формі Бернштейна:
\begin{multline*}
f_{\mbox{opt}}(x)=0.55-0.7\phi_0^9(x)+0.1\phi_1^9(x)
-1.3\phi_2^9(x)-0.9\phi_3^9(x)+\\+1.2\phi_4^9(x)
+0.8\phi_5^9(x)-0.4\phi_6^9(x)+0.2\phi_7^9(x)+0.8\phi_8^9(x)+0.2\phi_9^9(x).
\end{multline*}


\subsection{Модель Фрідмана (Friedman)}

Розглянемо так звану модель Фрідмана~\cite{Friedman} з десятьма
рівномірно розподіленими на $[0;1]$ вхідними змінними, тільки перші
п'ять з яких входять в реальну модель:
$$
y(\mathbf{x})=10\sin(\pi
x^1x^2)+20\left(x^3-\frac{1}{2}\right)^2+10x^4+5x^5+\mathcal{N}(0,1.0).
$$
Для навчальної вибірки згенеровані 500 точок, для прогнозування
згенеровані інші 500 точок. Оптимальні значення гіперпараметрів
$\beta=7.6$, $\epsilon=0.02$. Представлення моделі у формі
Бернштейна:
\begin{multline*}
f_{\mbox{opt}}(\mathbf{x})=0.51-0.13\phi_0^1(x^1)+0.13\phi_1^1(x^1)
-0.14\phi_0^1(x^2)+0.14\phi_1^1(x^2)+\\+0.01\phi_0^1(x^3)
-0.01\phi_1^1(x^3)-0.18\phi_0^1(x^4)+0.18\phi_1^1(x^4)-0.09\phi_0^1(x^5)+0.09\phi_1^1(x^5).
\end{multline*}
Як можна бачити, модель добре відображає рівнозначний вплив факторів
$x^1$, $x^2$. Також практичну незначність фактору $x^3$. І вдвічі
більший ефект від $x^4$, ніж від $x^5$.

\subsubsection{Спрощена модель Фрідмана}

Також іноді аналізують спрощену модель Фрідмана, яка має вигляд:
$$
y(\mathbf{x})=10\sin(\pi x^1x^2)+\mathcal{N}(0,1.0).
$$
Рис.~\ref{fig:smplfriedman} відображає результат ідентифікації ПРІАМ
на основі 10 точок і результат прогнозування останніх 20 точках.
\begin{figure}[ht]
\safepdf{\centerline{\includegraphics[height=9cm]{CHAPTER4/EPS/smplfriedman.pdf}}}
{\centerline{\psfig{figure=CHAPTER4/EPS/smplfriedman.eps,height=9cm}}}
\caption{ПРІАМ для спрощеної моделі
Фрідмана.}\label{fig:smplfriedman}
\end{figure}
Модель описується 10 опорними векторами. Повний розв'язок
представлено в таблиці~\ref{tbl:Solution-SimpleFriedman}. Показані
шість послідовних ітерацій байєсівської індукції. Початкова і
кінцева конфігурації характеристичного простору відповідно мають
вигляд:
$$
\mathbf{C}^{(0)}=\left(\begin{array}{ll}1&0\\0&1\end{array}\right),\quad
\mathbf{C}^{(\cdot)}=\left(\begin{array}{ll}2&2\\0&2\end{array}\right).
$$
Розклад опорних векторів:
\begin{multline*}
f_{\mbox{opt}}(\mathbf{x})=0.49-7.2k(\mathbf{x}_{1},\mathbf{x})-9.7k(\mathbf{x}_{2},\mathbf{x})
-4.2k(\mathbf{x}_{3},\mathbf{x})+1.8k(\mathbf{x}_{4},\mathbf{x})-\\-5k(\mathbf{x}_{5},\mathbf{x})+9.7k(\mathbf{x}_{6},\mathbf{x})+9.7k(\mathbf{x}_{7},\mathbf{x})
+4.9k(\mathbf{x}_{8},\mathbf{x})+9.7k(\mathbf{x}_{9},\mathbf{x})-9.7k(\mathbf{x}_{10},\mathbf{x}).
\end{multline*}
Представлення моделі у формі Бернштейна:
\begin{multline*}
f_{\mbox{opt}}(\mathbf{x})=0.49-0.6\phi_0^2(x^1)+0.4\phi_1^2(x^1)
+0.2\phi_2^2(x^1)-0.02\phi_{002}^2(x^1,x^2)-\\-0.29\phi_{011}^2(x^1,x^2)
+0.09\phi_{020}^2(x^1,x^2)-0.07\phi_{101}^2(x^1,x^2)+0.42\phi_{110}^2(x^1,x^2)-\\-0.13\phi_{200}^2(x^1,x^2)
-0.6\phi_0^2(x^2)+0.3\phi_1^2(x^2)+0.3\phi_2^2(x^2).
\end{multline*}


\subsection{Модель AMPG}

Розглянемо еталонну задачу моделювання витрат палива автомобілем. Це
так звана задача AMPG (automobile miles per
gallon)~\cite{MLRepository}. Вибірка даних містить інформацію про
споживання палива для різних автомобілів з відомими
характеристиками: об'ємом двигуна ($x^1$), кінськими силами ($x^2$),
вагою ($x^3$) та прискоренням ($x^4$). В експерименті брало участь
392 автомобілі, серед них 300 для навчання і 92 для оцінювання
якості узагальнення побудованої моделі. Оптимальні значення
гіперпараметрів $\beta=20$, $\epsilon=0.2$. Оскільки кількість
опорних векторів досить велика, наводимо представлення моделі тільки
у формі Бернштейна:
\begin{multline*}
f_{\mbox{opt}}(\mathbf{x})=0.27+0.07\phi_0^1(x^1)-0.07\phi_1^1(x^1)
+0.18\phi_0^1(x^2)-0.18\phi_1^1(x^2)+\\
+0.14\phi_0^1(x^3)-0.14\phi_1^1(x^3)+0.03\phi_0^1(x^4)
-0.03\phi_1^1(x^4).
\end{multline*}
Цей результат можна порівняти з методом SUPANOVA
С.Гуна~\cite{Gunn-Brown} на цьому ж модельному прикладі.

% Результати інших методів (AMPG)
% 0.0222 - 31.389 : PRIAM
% 0.024 - 34.173 : GMDH
% 0.026 - 37.12 : FGMDH
% 0.028 - 39.82 : RNN
